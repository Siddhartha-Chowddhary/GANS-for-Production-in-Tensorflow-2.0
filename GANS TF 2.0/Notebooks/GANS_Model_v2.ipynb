{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pM4ln-3lJTfv"
   },
   "source": [
    "# ***NOTE:-***\n",
    "The problem here is Generator's accuracy will go down, sometimes it happens with Discriminator also,  if tried to train in Tensorflow 2.0 it's more like a mode collapse and this problem occur  when you train the model from scratch  \n",
    "# but if you try to use the existing trained  model it works Great   \n",
    "\n",
    "\n",
    "### So if you want to train from scratch you can do so in version Tensorflow 1.14 and then save the model and then run the saved model in 2.0 for production **bold text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 642
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 52660,
     "status": "ok",
     "timestamp": 1567094229360,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "IHJEfovmjAsx",
    "outputId": "108250f8-0fb8-4552-d6e6-26778d72a38e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu==2.0rc0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/12/8c64cc62149cc21c70c55018502831bbf4d42bd62bed196df7de6830d21b/tensorflow_gpu-2.0.0rc0-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
      "\u001b[K     |████████████████████████████████| 380.5MB 57kB/s \n",
      "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.12.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (0.2.2)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (3.7.1)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (0.7.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.1.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.16.4)\n",
      "Collecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806 (from tensorflow-gpu==2.0rc0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
      "\u001b[K     |████████████████████████████████| 4.3MB 29.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.1.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.11.2)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.15.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (0.8.0)\n",
      "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601 (from tensorflow-gpu==2.0rc0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
      "\u001b[K     |████████████████████████████████| 501kB 48.0MB/s \n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow-gpu==2.0rc0)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/1a/ab5683d8e450e380052d3a3e77bb2c9dffa878058f583587c3875041fb63/opt_einsum-3.0.1.tar.gz (66kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 30.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (0.33.4)\n",
      "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (1.0.8)\n",
      "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0rc0) (0.1.7)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0rc0) (41.2.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0rc0) (0.15.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0rc0) (3.1.1)\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0rc0) (2.8.0)\n",
      "Building wheels for collected packages: opt-einsum\n",
      "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for opt-einsum: filename=opt_einsum-3.0.1-cp36-none-any.whl size=58500 sha256=ea712e2a43e18ef782ef1f2373bcb17dd88ffb9ba41a53006cf4c6137f0be56b\n",
      "  Stored in directory: /root/.cache/pip/wheels/91/98/8d/10e3d4e04c959597a411b91acd3695e9e2d210e68ce3427aad\n",
      "Successfully built opt-einsum\n",
      "Installing collected packages: tb-nightly, tf-estimator-nightly, opt-einsum, tensorflow-gpu\n",
      "Successfully installed opt-einsum-3.0.1 tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc0 tf-estimator-nightly-1.14.0.dev2019080601\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow-gpu==2.0rc0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 727,
     "status": "ok",
     "timestamp": 1567094231967,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "Kxot3m-QBGnD",
    "outputId": "576b1fe7-ae29-430e-c0f7-3677e4e97d6a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "#Loading the Data from Drive \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 2.0 Dependencies \n",
    "use these only if you want to Deploy it for production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iYnF0to2A873"
   },
   "outputs": [],
   "source": [
    "#Importing Are Dependencies \n",
    "#Tensorflow 2.0 version\n",
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
    "from tensorflow.keras.layers import LeakyReLU\n",
    "from tensorflow.keras.layers import UpSampling2D, Conv2D\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow 1.14 Dependencies \n",
    "use these only if you want to train the model completley from scratch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras \n",
    "from keras.layers import Input, Reshape, Dropout, Dense, Flatten, BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 801,
     "status": "ok",
     "timestamp": 1567094236692,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "4JlWULtOBJjl",
    "outputId": "e7bae3fa-aaab-469b-c932-af310d78ae4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-rc0'"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check if the Right Version is installed or not \n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 766,
     "status": "ok",
     "timestamp": 1567094243760,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "rcrYoPLcHRFM",
    "outputId": "8389c897-b828-49a3-f537-853d4a1529c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Will generate 64px square images.\n"
     ]
    }
   ],
   "source": [
    "#Our Hyperparameters for Images   \n",
    "GENERATE_RES = 2 # (1=32, 2=64, 3=96, etc.)\n",
    "GENERATE_SQUARE = 32 * GENERATE_RES # rows/cols (should be square)\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "\n",
    "#Our Hyperparameters for image Preview  \n",
    "PREVIEW_ROWS = 5\n",
    "PREVIEW_COLS = 7\n",
    "PREVIEW_MARGIN = 16\n",
    "SAVE_FREQ = 100\n",
    "\n",
    "# Size vector to generate images from\n",
    "SEED_SIZE = 100\n",
    "\n",
    "#Model Controller Parameters\n",
    "EPOCHS = 10000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "#Path  Configuration\n",
    "OUTPUT = 'Path/to/Output/'\n",
    "\n",
    "#Path to the Discriminator Model if you have\n",
    "DISCRIMINATOR_MODEL = 'Path/to/Discriminator'\n",
    "\n",
    "#Path to the Generator Model if you have\n",
    "GENERATOR_MODEL = 'Path/to/Generator' \n",
    "\n",
    "\n",
    "print(f\"Will generate {GENERATE_SQUARE}px square images.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p29xtoEPBS4S"
   },
   "outputs": [],
   "source": [
    "#Loading the Np format Data File  in the Training_data variable \n",
    "numpy_training_images = 'Path/to/Numpy_data_file/'\n",
    "Training_data = np.load(numpy_training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "BZn5SLjJBVUP"
   },
   "outputs": [],
   "source": [
    "#Building the Generator Network \n",
    "def Generator(seed_size, channels):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(4*4*256,activation=\"relu\",input_dim=seed_size))\n",
    "    model.add(Reshape((4,4,256)))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(256,kernel_size=3,padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(Activation(\"relu\"))\n",
    "   \n",
    "    # Output resolution, additional upsampling\n",
    "    for i in range(GENERATE_RES):\n",
    "      model.add(UpSampling2D())\n",
    "      model.add(Conv2D(128,kernel_size=3,padding=\"same\"))\n",
    "      model.add(BatchNormalization(momentum=0.8))\n",
    "      model.add(Activation(\"relu\"))\n",
    "\n",
    "    # Final CNN layer\n",
    "    model.add(Conv2D(channels,kernel_size=3,padding=\"same\"))\n",
    "    model.add(Activation(\"tanh\"))\n",
    "\n",
    "    input = Input(shape=(seed_size,))\n",
    "    generated_image = model(input)\n",
    "\n",
    "    return Model(input,generated_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "cellView": "code",
    "colab": {},
    "colab_type": "code",
    "id": "SLrVCm6GBYgl"
   },
   "outputs": [],
   "source": [
    "#Building the Discriminator Network \n",
    "def Discriminator(image_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=image_shape, padding=\"same\"))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "    model.add(BatchNormalization(momentum=0.8))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    input_image = Input(shape=image_shape)\n",
    "\n",
    "    validity = model(input_image)\n",
    "\n",
    "    return Model(input_image, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AmB4kTi6BanK"
   },
   "outputs": [],
   "source": [
    "#Function for saving the images \n",
    "from PIL import Image\n",
    "\n",
    "def save_images(cnt,noise):\n",
    "  image_array = np.full(( \n",
    "      PREVIEW_MARGIN + (PREVIEW_ROWS * (GENERATE_SQUARE+PREVIEW_MARGIN)), \n",
    "      PREVIEW_MARGIN + (PREVIEW_COLS * (GENERATE_SQUARE+PREVIEW_MARGIN)), 3), \n",
    "      255, dtype=np.uint8)\n",
    "  \n",
    "  generated_images = generator.predict(noise)\n",
    "\n",
    "  generated_images = 0.5 * generated_images + 0.5\n",
    "\n",
    "  image_count = 0\n",
    "  for row in range(PREVIEW_ROWS):\n",
    "      for col in range(PREVIEW_COLS):\n",
    "        r = row * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        c = col * (GENERATE_SQUARE+16) + PREVIEW_MARGIN\n",
    "        image_array[r:r+GENERATE_SQUARE,c:c+GENERATE_SQUARE] = generated_images[image_count] * 255\n",
    "        image_count += 1\n",
    "\n",
    "          \n",
    "  output_path = os.path.join(OUTPUT)\n",
    "  if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "  \n",
    "  filename = os.path.join(output_path,f\"train-{cnt}.png\")\n",
    "  im = Image.fromarray(image_array)\n",
    "  im.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6g01f1Oe-Er"
   },
   "outputs": [],
   "source": [
    "#Preparing the model to Train\n",
    "image_shape = (GENERATE_SQUARE,GENERATE_SQUARE,IMAGE_CHANNELS)\n",
    "optimizer = Adam(2e-4,0.5)\n",
    "\n",
    "#discriminator =  load_model(DISCRIMINATOR_MODEL)\n",
    "discriminator = Discriminator(image_shape)\n",
    "discriminator.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])\n",
    "#generator = load_model(GENERATOR_MODEL)\n",
    "generator =  Generator(SEED_SIZE,IMAGE_CHANNELS)\n",
    "\n",
    "random_input = Input(shape=(SEED_SIZE,))\n",
    "\n",
    "generated_image = generator(random_input)\n",
    "\n",
    "discriminator.trainable = False\n",
    "\n",
    "validity = discriminator(generated_image)\n",
    "\n",
    "combined = Model(random_input,validity)\n",
    "combined.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2243,
     "status": "ok",
     "timestamp": 1567094302466,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "H-r06IHuuEz6",
    "outputId": "456aa35f-a704-4a13-fdb9-83d125be6a35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 64, 64, 3)         2043011   \n",
      "=================================================================\n",
      "Total params: 2,043,011\n",
      "Trainable params: 2,041,475\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1713,
     "status": "ok",
     "timestamp": 1567094302469,
     "user": {
      "displayName": "Sid Killer",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mDMXbw4ZnMK2DRqjnpDJNCkmT-Y1LSs90u7OkZm=s64",
      "userId": "09987325173482547605"
     },
     "user_tz": -330
    },
    "id": "8UAC54tDuEl9",
    "outputId": "b75fec49-2cb5-41c5-e44b-218baf3658e5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0829 15:58:22.256295 140445732149120 training.py:2055] Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 1)                 6337601   \n",
      "=================================================================\n",
      "Total params: 12,671,234\n",
      "Trainable params: 6,333,633\n",
      "Non-trainable params: 6,337,601\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I85VDDtxDAZh"
   },
   "outputs": [],
   "source": [
    "#TRAINING!!!!\n",
    "EPOCHS = 10000\n",
    "\n",
    "Model_path = '/content/drive/My Drive/Zeus/Model'\n",
    "y_real = np.ones((BATCH_SIZE,1))\n",
    "y_fake = np.zeros((BATCH_SIZE,1))\n",
    "\n",
    "fixed_seed = np.random.normal(0, 1, (PREVIEW_ROWS * PREVIEW_COLS, SEED_SIZE))\n",
    "\n",
    "cnt = 1\n",
    "for epoch in range(EPOCHS):\n",
    "    idx = np.random.randint(0,Training_data.shape[0],BATCH_SIZE)\n",
    "    x_real = Training_data[idx]\n",
    "\n",
    "    # Generate some images\n",
    "    seed = np.random.normal(0,1,(BATCH_SIZE,SEED_SIZE))\n",
    "    x_fake = generator.predict(seed)\n",
    "\n",
    "    # Train discriminator on real and fake\n",
    "    discriminator_metric_real = discriminator.train_on_batch(x_real,y_real)\n",
    "    discriminator_metric_generated = discriminator.train_on_batch(x_fake,y_fake)\n",
    "    discriminator_metric = 0.5 * np.add(discriminator_metric_real,discriminator_metric_generated)\n",
    "    \n",
    "    # Train generator on Calculate losses\n",
    "    generator_metric = combined.train_on_batch(seed,y_real)\n",
    "    \n",
    "    # Time for an update?\n",
    "    if epoch % SAVE_FREQ == 0:\n",
    "        save_images(cnt, fixed_seed)\n",
    "        cnt += 1\n",
    "        print(f\"Epoch {epoch}, Discriminator accuarcy: {discriminator_metric[1]}, Generator accuracy: {generator_metric[1]}\")\n",
    "\n",
    "\n",
    "\n",
    "MODEL = '/content/drive/My Drive/Zeus/Designer_AI/Designer_AI_Models_and_Weights/Sports_Cars '\n",
    "#Models\n",
    "discriminator.save(os.path.join(MODEL,\"Discriminator_v2.h5\"))\n",
    "generator.save(os.path.join(MODEL,\"Generator_v2.h5\"))\n",
    "#Weights\n",
    "discriminator.save_weights(os.path.join(MODEL,\"Discriminator_weights_v2.h5\"))\n",
    "generator.save_weights(os.path.join(MODEL,\"Generator_weights_v2.h5\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uapO_twOf6og"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Designer_Ai_Model_v2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
